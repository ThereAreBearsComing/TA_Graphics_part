# 实时阴影
## 基于图片的实时阴影技术
### 平面投影映射
* **平面投影阴影**
    * 平面投影映射并不是一个基于图片的解决方案
    * **内容：**
        * 根据光的方向，把物体的每个顶点投影到平面地面上。
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/0c796b0c-c442-4432-a13f-db2833598ba5)
    * **数学原理：**
      * 相似三角形
      * 光Light所在的点L已知，V已知，P很容易就能求得
    * **缺点：**
      * 只能投影到平面（阴影的接收物只能是平面）
      * 投影物体必须在光线和平面之间

* **投影阴影**
    * **平面投影阴影的阴影接收物只能是平面，为了再曲面上得到阴影，做了以下改进：**
    * ** 投影阴影：**
      * 把光源当做一个相机/投影器
      * 然后将阴影投影渲染到一张纹理
      * 最后**渲染阴影接收者时**，将上一步得到的阴影合并进去
      * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/23229fd9-545c-46d9-a063-c8d25788e7e5)

* 投影阴影在Unity中的实现
![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/084c10c4-dfd8-4e1c-8b72-128a1659efa5)
    * 第一步，设置Project组件，通过它的参数使用给它的材质生成一个视锥体
    * 第二步，使用Render Texture生成一张纹理，将阴影绘制到纹理中
    * 第三步，将设置Project组件的物体和阴影纹理进行混合

### 阴影映射（ShadowMapping）
* **理解：阴影**
    * **如何确定“是不是阴影”**
        *  我们能看见+光能看见 = 正常渲染
        *  我们能看见 + 光看不见 = 阴影
    * **GAMES101中，讲过的关于阴影的理解：**
      * 是一个经典的双Pass做法
      * Pass1：从光源看向场景，记录看到点的深度
        * 需要从光源的位置渲染整个场景的深度图（这张图就是shadowmap）
      * Pass2：从相机看向场景
        * 再从相机位置渲染这个场景
      * 再投影回光源所在的图像上，比较在相机位置渲染和光位置的深度，结果可以这样理解：
        * 深度一致：说明相机和光都能看到
        * 深度不一致：我们能看到，但是光看不到 =>阴影
![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/9ae5d31c-e969-4d21-b1be-537fc34efbd9)

* **不同视角下的场景**
    * 相机（view）视角下：
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/ab808ef2-6378-40e8-aa33-b4ed4d9e5e4c)
    * 光源视角下（shadowmap）
      * 我们从光源看向场景的角度渲出一张深度图，这张深度图：
        * 离光源越近就越黑（0）；越远就越白（1）
        * 这张图就反映出了场景中物体的远近关系
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/8cec947b-03ff-4cc9-be79-87835602c418)

* **阴影映射的流程**
    * 首先，从光源的位置生成一张深度图（shadowmap）
    * 渲染物体
      * 每次渲染时，需要和shadowmap的深度做比较（深度测试）
    * 如果一个片元的深度>它在shadowmap中的深度，那么就认为它在阴影中

* **总结/注意事项：**
    * ShadowMapping本质上是一种图像空间做法，也就是说生成shadow这一步不需要这个场景的几何信息
    * ShadowMapping只能做硬阴影

### Unity中的屏幕空间阴影映射
* **步骤**
    * 渲染屏幕空间的深度贴图
    * 从光源方向渲染出shadowmap
    * **在屏幕空间**做一次阴影收集计算（Shadows Collector，将前两步生成的图做深度比较），
        * **这次计算会得到一张屏幕空间的shadowmap（Collect Shadows）**
        * 实际上就是对前两步的深度图做一个比较，得到一张新的深度图 
    * 在绘制物体时，用物体的**屏幕坐标uv**采样第三步中生成的屏幕空间shadowmap
* **从FrameDebugger查看过程**
<br>![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/030629ce-bf77-42b4-a749-e6e0f7b88e9d)
<br>![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/f08f3b39-25a0-4a2c-ae44-21fc64099ffb)

## 阴影映射的问题与优化
### 问题1：自阴影/自遮挡
* **自阴影：**
    * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/2c62c136-9e59-4e7e-baf9-e3d90f6ed439)![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/9d28838b-250b-49ee-b3b8-dacae8d37414)
    * 因为shadowmapping的分辨率有限，离散的采样点以及数值上的偏差可能造成不正确的自遮挡效果
    * 也被称为Z-Fighting/阴影粉刺（Surface Acne）

* **为什么会有自阴影：**
    * 出现自阴影的原因：
        * 如下图所示，在映射shadowmap的过程中，下边一大个范围内的深度都是一个值（shadowmap的一格）
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/0fb7b9a5-7756-4244-9915-e6f253bd7175)

* **自阴影的解决？**
    * 深度偏移（Depth Bias），增加深度偏移会使该像素向光源靠近
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/cf1a6328-fac6-43c1-a204-3e09105da227)
    * 法线偏移（Normal Bias），沿着表面法线方向向外偏移
    * 偏移单位是shadowmap的纹素

* **深度偏移会造成的问题（Peter Panning）**
    * 当Bias设置过大时，还会导致下边这种问题：**Peter panning（学术界叫作detached shadow）**
        * //Peter Panning名称的由来：Peter是西方漫画中的人物，他和影子是可以分开的
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/525a72b3-b744-443a-bfe8-84f81c6ce1b1)

* **GAMES101补充理解**
    * **为什么会有自阴影情况**
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/7f74facd-e41b-47bd-830e-d5aedfd102f8)
        * 从light往场景看（左边太阳的线）时，比如沿着某一个像素往过看，看到的位置`（红色斜线）就是像素所代表的深度`，（假设任何一个像素是一个常值的深度）。也就是说，`在shadowmap看来，场景离散成了图中红色斜线形成的结果`。
        * 第二个pass渲染的时候，从camera出发（右边连着眼睛的蓝色虚线），常规操作：连向light （左边蓝色虚线），这段虚线长度就是它的深度
        * **问题：** `在shadowmap记录的对应的深度是橙色的部分（更浅），而实际上从相机看向这个像素，它的深度应该是被橙色部分遮挡住的点（两条蓝色虚线的交点）`→这就是自遮挡情况
        * **特殊情况：**
            * 光垂直的，从上往下照时候，不存在问题
            * 光非常偏的时候，问题最大（例如：塞尔达中夕阳西下时）
            * //不难理解，斜着的时候就完全被挡住了，垂直的时候就不会被遮挡，图已经画的很清楚了
    * **如何解决这个问题：**
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/27146d05-b54d-4d44-8751-3a79ee2911c9)
        * 加上一个所谓的Bias避免自遮挡（图中橙色那段）
            * 认为shadowmap上的深度，明显比实际的深度小的情况下，橙色的这一段障碍物就不算了
            * bias可以不是一个常数，可调整，如果垂直打光，可以非常小，夹角很大的情况，可以更长一点

* **Unity中实现自阴影的优化**
    * 思路：
        * 在生成shadowmap时去做Bias（偏移）
![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/f62d6f2b-df60-401f-8cd8-4509aa39273b)

### 走样
* **走样问题**
    * 走样，最明显的表现就是锯齿，我们可以看下边的例图
        * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/1471dcd7-74fb-4027-9dd0-008c0cef2c1e)
* **走样问题的具体内容和解决方法**
    * **在什么阶段会走样？**
        * 初始采样：渲染shadowmap时
        * 重采样：从相机位置对shadowmap进行重采样时
    * **初始采样阶段**
    * 最严重的问题：**透视走样**
        * 透视走样是如何形成的？
            * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/92f539ad-2e1c-499a-8718-741fbd4ff83f)
            * shadowmap在世界空间均匀分配（左图的三段纹素对应的世界空间的一个像素大小是一样的）
            * **经过透视投影后**，根据近大远小的原理，原来大小不一样的近平面和远平面，在屏幕内占的像素便一样了。（右图）
            * 这时远平面对应在shadowmap中的纹素就比近平面大了
            * 这种离相机近的部分走样的情况一般称为**透视误差**
        * **  如何解决？**
            * 思路1：
                * 因为我们在使用shadowmap时，相机是经过透视投影的，但生成shadowmap时并没有经过透视投影
                * 所以我们在生成shadowmap时就进行一次透视投影
            * 思路2：
                * 尽量减少近平面和远平面之间的像素差距
                * Unity中的级联阴影映射就是用的这个思路
    * **重采样阶段**
        * shadowmap可以理解为一张动态生成的纹理
            * 重采样误差的解决方法：滤波（Filter）
            * 滤波：在图像处理中，通过滤波强调一些特征或者去除图像中一些不需要的部分
            * 滤波是一个领域操作算子，利用给定像素周围的像素的值决定该像素的最终输出值
        * 补充：
            * 滤波就是抹掉特殊频率的东西
            * 高通滤波 = 边界
            * 低通滤波 = 模糊
            * //滤波（Filtering）=卷积（Convolution）=平均（Averaging）
        * 阴影滤波：
            * 使用一部分shadowmap采样点来计算某个指定View采样点的最终阴影结果的方法
        * PCF滤波
            * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/1767bc4d-83d1-4247-af94-1b3fa10248e5)
            * 一句话总结：PCF中，不是取shadowmap上一个点的深度去比较，而是：取shadowmap上任意一个点的周围一个Filter大小的区域（滤波核），将这个区域的所有点都去做一次深度比较（0或1的结果），最后再对这些结果做一个平均（不是非0即1的结果，而是一个权重值/像素的颜色值）
            * 采样数K（其实就是Filter的大小）
                * 可以是规则滤波，3*3或者5*5等
                * 也可以采用泊松滤波（Poisson DIsk）的形式来分布一定数量的采样点
                * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/0b778556-9f32-4180-9886-92e6c1a0fced)
                * 详情看后边扩展整理

* **级联阴影映射（Cascade Shadowmap）**
    * 是透视走样最有效的解决方案
    * 把视锥体分割为多个子视锥体，为每个子视锥体计算相等大小的shadowmap
    * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/22eb507e-ab25-48de-be1b-df3a3b422ff0)
    * //就是给shadowmap不同位置不同的分辨率

## 补充/扩展知识
### 硬阴影和软阴影
* 上边有提到过ShadowMapping的做法只能做硬阴影，那么什么是硬阴影和软阴影呢？
* **软硬阴影的区别：** 硬阴影没有一个明显的从有阴影到没有的过度/界限（因为绝大多数的生活中的光源是面光源）
* ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/06a908f6-3c97-4d13-9692-ecbb81e3e486)

### PCF和PCSS
* PCSS是古老的方法，是经过探索之后最终的选择（因为现在的降噪技术ok）
* PCSS是产生真正软阴影的方法
* **PCF**
   * 值得注意的是，PCF最早研究出来是为了做阴影边缘的反走样的
   * 用PCF做软阴影就是PCSS
   * **我们先搞清楚PCF不是什么：**
      * 不是对已经有锯齿的阴影做Filter，而是在阴影判断时做Filter（可以类比反走样：先模糊再采样）
      * 不是对shadowmap做Filter
* **PCF做了什么？**
  * 我们先回顾一下，之前如何判断一个点在不在阴影中：
    * shading point 连向light，然后和shadowmap上的 **一个像素** 做深度比较（结果是0或1）
  * **PCF和我们之前操作的区别：**
    * 要判断这个shading point是不是在阴影中，我们不去找它对应在shadowmap上的一个像素，而是找 **这个像素周围的一圈像素**，把这 **一圈的每个像素的深度都去和实际的深度做一次比较（多个0或1的结果）**
    * 做完比较之后，再把它们平均 **（不是非0即1的结果）**
  * **举个例子：**
  * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/d531b729-33d1-411c-b4c3-3242d910c93e)
  * 如上图
   * 不和shadowmap上的一个点做比较，而是和上图中黑框是3×3的区域的9个像素做9次比较
   * shadowmap中的这九个像素和当前shading point点P的深度做9次计较，得到9个非0即1的结果
   * 将这个9个结果取一个平均值，就是最后的Visibility0.667（不再是非0即1的值）

* ** Filter的大小重要吗？**
   * 如果小（比如1×1 = 没做Filter），结果是锐利（sharpener）对应硬阴影
   * 如果大，结果是softer，对应软阴影
   * 既然Filter的大小可以决定阴影的软硬，我们不妨这样理解： 软阴影 = 硬阴影做一个非常大的Filter

* **现实世界的软硬阴影**
   * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/6b1ff939-43bd-4d1e-8ccb-4ef63236c391)
   * 阴影在笔尖的地方是硬的，远的地方就很虚（软）
   * 也就是说：阴影的软硬和遮挡物的距离有关（注意：不是和光源的距离）
   * ** 关键结论： **
     * 要想做一个软阴影的效果，应该给硬阴影各个位置不同大小的filter
  * **那么这个不同位置不同的Filter的大小怎么解决呢？**
     * 既然阴影的软硬和遮挡物距离有关，那么我们就做一个定义
     * 定义一个blocker distance（遮挡物和阴影接收物的距离） 
     * 更准确的说法：相对的、平均的、投射的遮挡物的深度
  * **到此为止我们做个总结：**
     * 我们知道了PCF怎么做
     * 要做PCF，我们还需要知道Filter的大小，接下来就是PCSS的舞台了
* **PCSS**
   * PCSS示意图
      * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/f5ebf6a6-6a61-49db-95f1-b4440635e160)
   * 上方黄色线段表示Light（光），中间绿色线段表示Blocker（遮挡物），下边蓝色线段就是Receiver（阴影的接收物）
   * 将Light 和Blocker连到Receiver上，就可以看到很明显的相似三角形
   * 通过相似三角形关系我们就可以得到以下信息：
      * 蓝色虚线=d<sub>Receiver</sub>，绿色虚线 = d<sub>Blocker</sub>
      * **绿色虚线 /（蓝色虚线 - 绿色虚线） = W<sub>Light</sub> / W<sub>Penumbra</sub>**
      * 当遮挡物（Blocker）离接收阴影物的距离变小，WPenumbra也会变小（阴影变硬），反之变大（阴影更软）
      * W<sub>Penumbra</sub>就是filter的范围
   * 我们继续分析
   * 现在唯一的问题就是：该Filter多大？
      * **这取决于 light的大小，也取决于blocker depth d<sub>blocker</sub>**
      * 平常指的blocker depth是说average blocker depth，意思就是：对于一个shading point，要看在一定的范围内，有多少能够挡住它的，在shadowmap上记录的像素，这些像素记录的深度的平均值是什么
   * 这样一来，人们就可以把PCF的思想用在PCSS上了
   * **PCSS的核心思想：**
      * 为了知道Filter要多大，得知道blocker到shading point的距离是多少
   * **PCSS的算法：**
      * **Step1：Blocker search**
         * 从shading point连向点光源，找到一个点，去周围的某一个区域，来判断是不是在阴影里，如果在，那个像素就是一个blocker，记下来。所有的都走一遍，记下所有的blocker的深度记下来，然后取一个平均。
      * **Step2：Penumbra estimation**
          * 用average blocker 计算 filter size
      * **Step3：做PCF**
          * 既然知道了Filter的大小，就可以计算PCF了
          * 第2、 3步和PCF没有区别：`第一步之后，知道了blocker的距离，就可以计算filter size`，知道filter多大，就和之前PCF做法完全一样。
      * 在第一步Blocker search时，在多大的范围内search呢（在多大的范围找blocker）？
        * 是一个鸡生蛋蛋生鸡的问题：
          * 本来就是为了确定在shadowmap的周围多大的范围做PCF，为了知道这个信息，就要知道average blocker depth信息。要知道average blocker depth的话，`也得先取一个区域`找average blocker，再把他们平均起来。
        * 取多大？
          * 可以取固定大小的范围
          * 更好的方法：shading point连向light，覆盖shadowmap的区域（红色区域），我们只在这个区域范围内找blocker
          * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/06fd3c31-2d56-4e5b-b01b-18d151cfa63a)
   * **其他补充**
      * 开销恐怖，会很慢
         * 第一步，第三步，每个texel都要走一遍
         * 工业界的正常处理方案：进行稀疏采样（噪声大，//现在能做降噪处理）
         * 其他办法：VSSM
       * 一个理解：**PCSS的核心就是一个适应性的fliter size**

### VSSM
* 针对解决了PCSS中第一步和第三步慢的问题（甚至不用做任何采样和循环，但是做了大量的近似）
* 对应的是GAMES202-L4部分
* 考虑的篇幅问题，就不再整理了，我直接贴笔记地址，感兴趣的自行扩展
* https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/gcuczo


### Moment Shadowmapping
* VSSM的发明是为了解决PCSS的问题，其实VSSM自己同样会有问题
* 当分布非常简单的情况下，就会出错（分布描述的不准）
* Moment ShadowMapping解决了分布描述不准的问题








## Unity内建Shadow实现方式
含阴影的shader，这里的阴影包含接收阴影和产生阴影：
```HLSL
Shader "MyCustom/Chapter27_PhongWithBuildinShadow"
{
    Properties
    {
        _MainTex            ("Texture",             2D)             = "white" {}
        _Diffuse            ("_Diffuse",            Color)          = (0.5, 0.5, 0.5, 1)
        _SpecularPower      ("_SpecularPower",      Range(0, 150))  = 20
        _SpecularIntensity  ("_SpecularIntensity",  Range(0, 10))   = 1.5
    }
    SubShader
    {
        CGINCLUDE
        float _specular(float3 viewDir, float3 lightDir, float3 normal, float power, float intensity)
        {
            float3 _viewDir = normalize(viewDir);
            float3 _lightDir = normalize(lightDir);
            float3 _normal = normalize(normal);

            float3 halfVector = normalize(_lightDir + _viewDir);
            float hdotn = max(0, dot(halfVector, _normal));
            float specular = pow(hdotn, power) * intensity;
            return specular;
        }
        ENDCG

        Tags { "RenderType"="Opaque" }
        LOD 100

        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #pragma multi_compile_fwdbase

            #include "UnityCG.cginc"
            #include "Lighting.cginc"
            #include "AutoLight.cginc"

            // 使用unity内建的阴影，需要:
            // SHADOW_COORDS(): 声明阴影纹理坐标
            // TRANSFER_SHADOW: 将顶点从模型空间转换到光源空间
            // UNITY_LIGHT_ATTENUATION: 对阴影贴图进行采样
            // 通过调用fallback "specular"会查找到内建的pass

            struct appdata
            {
                float4 vertex       : POSITION;
                float2 uv           : TEXCOORD0;
                float3 normal       : NORMAL;
            };

            struct v2f
            {
                float2 uv           : TEXCOORD0;
                float3 worldNormal  : TEXCOORD1;  
                float3 worldPos     : TEXCOORD2;  
                float4 pos       : SV_POSITION;
                SHADOW_COORDS(4)
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;

            float4 _Diffuse;
            float _SpecularPower;
            float _SpecularIntensity;

            v2f vert (appdata v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                TRANSFER_SHADOW(o);

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                float3 lightDir = UnityWorldSpaceLightDir(i.worldPos);
                float3 viewDir = UnityWorldSpaceViewDir(i.worldPos);
                float3 specular = _LightColor0.rgb * _specular(viewDir, lightDir, i.worldNormal, _SpecularPower, _SpecularIntensity);

                float3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                float3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(i.worldNormal, lightDir));

                UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

                float4 finalColor = 1;
                finalColor.rgb = ambient + (diffuse + specular) * atten;

                return finalColor;
            }
            ENDCG
        }

        Pass
        {
            Tags {"LightMode"="ForwardAdd"}
            Blend One One

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #pragma multi_compile_fwdadd

            #include "UnityCG.cginc"
            #include "Lighting.cginc"
            #include "AutoLight.cginc"

            struct appdata
            {
                float4 vertex       : POSITION;
                float2 uv           : TEXCOORD0;
                float3 normal       : NORMAL;
            };

            struct v2f
            {
                float2 uv           : TEXCOORD0;
                float3 worldNormal  : TEXCOORD1;  
                float3 worldPos     : TEXCOORD2;  
                float4 vertex       : SV_POSITION;
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;

            float4 _Diffuse;
            float _SpecularPower;
            float _SpecularIntensity;

            v2f vert (appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                float3 lightDir = UnityWorldSpaceLightDir(i.worldPos);
                float3 viewDir = UnityWorldSpaceViewDir(i.worldPos);
                float3 specular = _LightColor0.rgb * _specular(viewDir, lightDir, i.worldNormal, _SpecularPower, _SpecularIntensity);

                float3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(i.worldNormal, lightDir));
                
                float atten = 1.0;
                #if defined (POINT)
                    float3 lightCoord = mul(unity_WorldToLight, float4(i.worldPos, 1)).xyz; 
                    atten = tex2D(_LightTexture0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
                #endif
                float4 finalColor = 1;
                finalColor.rgb = (diffuse + specular) * atten;

                return finalColor;
            }
            ENDCG
        }

        //Pass
        //{
        //    Tags {"LightMode"="ShadowCaster"}
        //}
    }
    Fallback "Specular" // 使用内建的pass
}
```
在Pass中增加：
* SHADOW_COORDS(): 声明阴影纹理坐标
* TRANSFER_SHADOW: 将顶点从模型空间转换到光源空间
* UNITY_LIGHT_ATTENUATION: 对阴影贴图进行采样
* 通过调用fallback "specular"会查找到内建的pass, 也可以自己写
* 注: 在多光源处理pass中没有加入这些，所以点光源无法产生阴影。
<br>![image](https://user-images.githubusercontent.com/74708198/233797155-bd93e6e6-aeb1-40f4-b7bd-b4d37c926802.png)

### 自定义shadow
ShadowMap的实现主要分为两个pass:

<br>**第一个pass：** 在光源位置创建一个深度摄像机，以光源位置作为视点，将每个像素点的深度值（z-depth）也就是距离光源最近的对象距离记录在 Z-buffer 中，生成深度图
<br>**第二个pass：** 从正常摄像机渲染场景，将每个fragment 到光源的距离和 Shadow Map 中保存的深度值进行比较，如果大于后者则说明被其他物体遮挡处于阴影之中
<br>![image](https://user-images.githubusercontent.com/74708198/233792279-48a2f86d-d01b-4694-a252-573842a246e4.png)

### 

### Shadow Map的问题以及优化方案

Shadow Acne: 阴影的产生和深度纹理的像素是相关的。深度纹理像素值越高，shadow acne的效果相对来说越小，然而shadow acne不可能通过提高像素来完全消除。因为只要光线和法向量的夹角不是90度，永远会有一部分的geometry会被判定处在阴影当中。这个问题可以通过给深度值加一个小小的bias来解决。通过法向量的和光线的夹角来判断bias要更为准确:
<br>float bias = max(max_bias * (1.0 - dot(normal, lightDir)), min_bias); 
<br>![image](https://user-images.githubusercontent.com/74708198/233792348-6137cd07-6fa7-4a1f-9803-998792032610.png) ![image](https://user-images.githubusercontent.com/74708198/233792353-0b843957-4493-443d-b592-53abf09ae89b.png)

阴影边缘抗锯齿: PCF(Percentage Closer Filtering)通过对附近像素多次采样求平均来实现阴影边缘抗锯齿，达到软阴影的效果
<br>![image](https://user-images.githubusercontent.com/74708198/233792383-dca1dc21-1ec4-4e3e-9921-5a2ec0a25e93.png) ![image](https://user-images.githubusercontent.com/74708198/233792385-7dca4441-243d-4af1-8f84-3487bde48dc3.png)




