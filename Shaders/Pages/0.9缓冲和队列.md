# Buffer and Queue

## Buffer

Frame Buffer 帧缓冲
<br>机算机的内存结构，用于保存屏幕上出现的每个像素的颜色讯息
<br>![image](https://user-images.githubusercontent.com/74708198/224555945-a11dd500-b4c9-4a25-aa5a-77fa61443814.png)

<br>片段着色器在写入帧缓冲之前会进行一系列测试：Alpha测试、模板测试、深度测试

<br>帧缓冲：单缓冲和双缓冲。双缓冲为了解决一帧绘制数据太慢，没有绘制完就绘制下一帧的问题

<br>单缓冲：![image](https://user-images.githubusercontent.com/74708198/224736625-3e847f59-ca2e-47e9-b6e9-f509df4c554f.png)

<br>双缓冲：![image](https://user-images.githubusercontent.com/74708198/224736753-6605eda8-6c60-4dbc-8abc-ce077404603c.png)

## 常见的帧缓冲 
* Depth Buffer （深度缓冲，Z Buffer）
    * 大小和 Frame Buffer一样，但储存的是每个像素的深度信息 (离画面的远近)
    * 先经过检查，此像素是否在 Depth Buffer 有值
    * 在 SubShader中可以使用 ZWrite Off关闭 Depth Buffer的值写入
    * 或在SubShader pass struct中使用 ZWrite On, ColorMask启用半透明 Depth Buffer写入
* Color Buffer （颜色缓冲）
    * 储存的是每个像素的颜色信息
    <br>8 bit = 2^8 = 256 (1 byte)
    <br>16 bit = 2^16 = 65536 (64k色，2 byte)
    <br>24 bit = 2^24 = 16777216 (24位真彩色，3 byte)
    <br>1920 * 1200分辨率，使用24位真彩色，会占用多少显存？
    <br>视频存储器＝图形分辨率 × 色彩精度／8
    <br>1920 * 1200 * (24 / 8)(byte) / 1024 /1024 = 6.59M
* G - Buffer （几何缓冲）
    * 在"延迟渲染" 中使用
* Stencil Buffer （模板缓冲）
    * 控制从场景到 Frame Buffer 的像素，可以做出遮罩类的效果

## 深度图采样案例
<br>使用脚本将深度缓存如一张Rendetexture
```HLSL
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

[ExecuteInEditMode]
public class Chapter_10_DepthCamera : MonoBehaviour
{
    // 声明 变量
    public Material mat;

    public Material displayZMat;

    //声明生成图像大小
    public int width = 512;
    public int height = 512;

    // 声明一个贴图将贴图贴出去
    public RenderTexture rt;

    //需要有个摄像机
    private Camera cam;

    // Start is called before the first frame update
    void Start()
    {
        // 用GetComponent查找当前脚本是否在相机<Camera>上，有则拿到相机，赋值为cam
        cam = GetComponent<Camera>();
        // 标记为采集的时深度图
        cam.depthTextureMode = DepthTextureMode.Depth;

        // 声明RenderTexture的大小位深（宽，高，24位真色彩）到rt
        rt = new RenderTexture(width, height, 24);
        // 将图给予targetTexture，即让相机将每帧渲染的图像保存到RenderTexture，即rt
        cam.targetTexture = rt;
    }

    // Update is called once per frame
     void Update()
     {
        Texture2D tex = getTexture2D(rt);
        // 如果能拿到2d贴图rt，且不等于0，则用.SetTexture 传递绘制在上边
        if (displayZMat != null && tex != null)
            displayZMat.SetTexture("_MainTex", tex);
     }

    // 所有的计算在OnRenderImage里
    private void OnRenderImage(RenderTexture source, RenderTexture destination)
    {
        // 如果有材质球的时候！！ 不然报错
        if (mat != null)
            Graphics.Blit(source, destination, mat); // 内置的函数，将当前的摄像机捕捉到的RenderTexture经过最开始声明的我们要传入的材质球mat处理
    }

    // 如何将RenderTexture转化位texture2d
    Texture2D getTexture2D(RenderTexture rt)
    {
        // 如果rt为0则返回0
        if (rt == null)
            return null;

        int width = rt.width;
        int height = rt.height;

        Texture2D tex = new Texture2D(width, height, TextureFormat.ARGB32, false); //false不生成mipmap
        RenderTexture.active = rt;
        // 读取.ReadPixels（用矩形控制 Rect（以左上角为原点0，0点，读取范围），写入到目标texture2d从的原点开始写入，即0，0左上角）
        tex.ReadPixels(new Rect(0, 0, width, height), 0, 0);
        tex.Apply();

        return tex;
    }
}
```

将深度贴图存为材质的Shader
```HLSL
Shader "MyCustom/Chapter10_ZBuffer"
{
    Properties
    {
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" }
        LOD 100

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            // make fog work
            #pragma multi_compile_fog

            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex       : POSITION;
            };

            struct v2f
            {
                float4 vertex       : SV_POSITION;
                float4 projPos      : TEXCOORD0;
            };

            //声明一个纹理
            uniform sampler2D _CameraDepthTexture;

            v2f vert (appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                // Unity内置函数
                o.projPos = ComputeScreenPos(o.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                // 转换到0~1空间 ( 采集深度纹理内置函数 ( _CameraDepthTexture, 将屏幕坐标系下的位置信息作为UV采集的内置函数 (i.projPos)).r)
                float depth = Linear01Depth(tex2Dproj(_CameraDepthTexture, UNITY_PROJ_COORD(i.projPos)).r);
                return depth;
            }
            ENDCG
        }
    }
}
```
![image](https://user-images.githubusercontent.com/74708198/224743389-67f91b91-93d1-4eef-b9f2-f41e759f6e28.png)


## Rendering Quene
* Unity的实体几何 (Geometry) 是从前到后渲染的 (先画近在画远)
  * 如果 Depth Buffer已经有值，就会直接忽略新的像素
  * 可以避免重复将像素写入 Frame Buffer

* 正向渲染 Forward Rendering
  * 可以渲染半透明物件
  * 渲染单个对象
  <br>Geometry => VertexShader => Geometry Shader => Fragment Shader Lighting => Frame Buffer

  * 渲染多个对象，每个对象都需要计算环境中所有光线
  <br>Geometry => VertexShader => Geometry Shader => Fragment Shader Lighting
  <br>Geometry => VertexShader => Geometry Shader => Fragment Shader Lighting
  <br>…
  <br>Geometry => VertexShader => Geometry Shader => Fragment Shader Lighting
  <br>All => Frame Buffer

* 延迟渲染 Deferred Rendering
  * 适合用在光源很多的时候
  * 渲染单个对象
  <br>Geometry => VertexShader => Geometry Shader => Fragment Shader => G-Buffer => Lighting => Frame Buffer

  * 渲染多个对象，照明计算只会进行一次
    <br>Geometry => VertexShader => Geometry Shader => Fragment Shader
    <br>Geometry => VertexShader => Geometry Shader => Fragment Shader
    <br>…
    <br>Geometry => VertexShader => Geometry Shader => Fragment Shader
    <br>All => G-Buffer => Lighting => Frame Buffer

* 使用渲染队列控制目标的绘制顺序

* 预设列队
    <br>Background => Geometry => AlphaTest => Transparent => Overlay
    <br>半透明渲染需要先有与物件后方不透明物件重叠的像素颜色，才能够进行颜色混合，所以顺序得在 Geometry之后

* 指定 Render Queue Tag
```HLSL
    Tags { "Queue" = "Background " }		   // 背景，一般天空盒之类的使用这个标签，最早被渲染
    Tags { "Queue" = "Geometry" } 			   // (default)  适用于大部分不透明的物体
    Tags { "Queue" = "AlphaTest" }             // 如果Shader要使用AlphaTest功能 使用这个队列性能更高
    Tags { "Queue" = "Transparent" }           // 这个渲染队列在AlphaTest之后，Shader中有用到Alpha Blend 
                                               // 的，或者深入不写入的都应该放在这个队列 
    Tags { "Queue" = "Overlay" }		       // 最后渲染的队列，全屏幕后期的 都应该使用这个

    Tags { "Queue" = "Geometry + 100" }        //也可以再加上自定数值
```

* 在 Inspector里 Renderer Queue可以直接输入想要的值，不被预设列队限制
    <br>![image](https://user-images.githubusercontent.com/74708198/224739677-e0f76699-4606-4597-b612-4023e93e4818.png)

### 半透明渲染队列案例

```HLSL
Shader "MyCustom/Chapter10_IntersectionHighlight"
{
    Properties
    {
        _RegularColor   ("Regular Color",       Color) = (1, 1, 1, 0.5)
        _HighlightColor ("Highlight Color",     Color) = (1, 0, 0, 1)
        _Threshold      ("Threshold",           float) = 1
    }
    SubShader
    {
        Tags { "RenderType"="Transparent" "Queue" = "Transparent"}
        LOD 100

        Pass
        {
            Blend SrcAlpha OneMinusSrcAlpha
            ZWrite Off

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            // make fog work
            #pragma multi_compile_fog

            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex       : POSITION;
            };

            struct v2f
            {
                float4 vertex       : SV_POSITION;
                float4 projPos      : TEXCOORD0;
            };

            uniform sampler2D _CameraDepthTexture;
            float4 _RegularColor;
            float4 _HighlightColor;
            float _Threshold;

            v2f vert (appdata v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.projPos = ComputeScreenPos(o.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                float4 finalColor = _RegularColor;

                // 从深度信息纹理读取当前顶点距离到视角空间下的深度值()
                float sceneZ = LinearEyeDepth(tex2Dproj(_CameraDepthTexture, UNITY_PROJ_COORD(i.projPos)).r);

                // 真实的从当前顶点到摄像机距离
                float partZ = i.projPos.z;

                float diff = sceneZ - partZ;

                if (diff <= _Threshold)
                {
                    float v = abs(diff) / _Threshold;
                    finalColor = lerp(_HighlightColor, _RegularColor, v);
                }

                return finalColor;
            }
            ENDCG
        }
    }
}
```
![image](https://user-images.githubusercontent.com/74708198/224743283-7820202a-e742-429e-954a-3bb14063abb8.png)

