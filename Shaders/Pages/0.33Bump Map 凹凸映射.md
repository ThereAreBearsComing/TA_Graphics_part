# Bump Map 凹凸映射
## BumpMapping介绍
* 描述一个物体绘制在屏幕上（表达物体的细节）
  * 宏观尺度
    * 特征可能覆盖很多个像素
    * 由顶点、三角形、其他几何图元表示
    * 例如：角色的四肢、头部
  * 中观尺度
    * 特征可能覆盖几个像素
    * 描述了宏观和微观尺度之间的特征
    * 包含的细节比较复杂，无法用单个三角形进行渲染
    * 细节相对较大，可以被观察者看到几个像素 以上的变化
    * 例如：人脸上的皱纹、肌肉的褶皱、砖头的缝隙
  * 微观尺度
    * 特征可能是一个像素
    * 通常在着色模型，写在像素着色器中，并且使用纹理贴图作为参数
    * 模拟了物体表面微观几何的相互作用
    * 例如：
      * 有光泽的物体表面是光滑的、漫反射的物体，在微观下表面是粗糙的 
      * 角色的皮肤和衣服看起来也是不同的，因为使用了不同的着色模型/不同的参数

* Bump Mapping
  * 模拟中观尺度的常用方法之一，可以让观察者感受到比模型尺度更小的细节
  * 基本思想：
    * 在纹理中将尺度相关的信息编码进去
    * 着色过程中，用受到干扰的表面去代替真实的表面
    * 这样一来，表面就会有小尺度的细节
  * 原理：
    * 从物体表面的贴图进行变化然后再进行光照计算的一种技术
    * 主要的原理是通过改变表面光照方程的法线，而不是表面的几何法线，或对每个待渲染的像素在计算照明之前都要加上一个从高度图中找到的扰动，来模拟凹凸不平的视觉特征
    * 例如：
      * 给法线分量添加噪音（法线映射贴图）
      * 在一个保存扰动值的纹理图中进行查找（视差映射、浮雕映射贴图）
    * 是一种提升物体真实感的有效方法， 且不用提升额外的几何复杂度（不用改模型）
  * 列举一个使用法线贴图的效果
    * 可以看到，使用了法线贴图的有了明显的立体感和细节
    * 对于中间的高亮部分，左边的都是均匀的，而右边即使是很高亮度的部分也能看到阴影
    * ![image](https://user-images.githubusercontent.com/74708198/237039133-26c93a3d-206f-4a78-8768-d58ac63e4271.png)

* Bump Mapping（凹凸映射）的分类
* ![image](https://user-images.githubusercontent.com/74708198/237039332-fc17a54c-e49c-44cc-a377-fc032810991c.png)
  * 用处
    * 非常广泛，如增加模型的细节效果、或者做特殊的画面表现
  * 最常用的：
    * 法线映射，增加法线贴图后，会对局部的物体表面产生扰动，进而改变明暗关系，来达到增加表面细节的效果
  * 三种映射都会用到法线贴图

## 法线映射
### 原理
* 法线贴图：存有物体局部表面法线信息的一张贴图
* 使用过程：
  * 在计算光照时，程序会去读取法线图，冰获取到当前像素点的法线信息，结合光照信息进行光照计算
* 优点：
  * 使用法线贴图来计算光照，可以让物体表现出更多丰富的细节，且随着光照方向的变化而变化，这是普通的贴图做不到的
* 生成:
  * 法线贴图一般由高模映射到对应的低模上来生成
  * 对于金属、木头这类细节丰富的物体，可以借助程序化的软件，如PS、SD来生成

### 实现
* 存储：切线空间
  * 法线的存储，一般会放到模型的切线空间中
  * **切线空间:**
    * 以物体表面的切线，副切线和法线组成的几何空间
    * 每个顶点都有属于自己的**切线空间**，这个空间的原点是顶点本身，z轴是顶点的法线方向（n），x轴是顶点的切线方向（t），y轴有前边两个轴叉乘而来，被称为副切线（b）或者副法线
    * 可以参考入门精要第七章部分
    * ![image](https://user-images.githubusercontent.com/74708198/237042331-46ff34b6-8e2d-4d2c-9ab0-6f735a9beb7a.png)
  * 在计算光照时，需要把相关的向量放在统一的坐标系下进行运算。此时就需要不同空间坐标的转换矩阵（世界空间转切线空间/切线空间转世界空间）

* 世界空间和切线空间的转换
  * 将世界坐标系下顶点的**法线（Normal）**、**切线（Tangent）**、**副切线（Bitangent）** 作为切线空间坐标系的正交基。用这三个向量的标准正交基构建转换矩阵。对应关系为：法线方向作为z轴，切线方向作为x轴，副切线方向作为y轴
  * 转换矩阵:
    * 切线空间到世界空间的转换矩阵为一个3×3的旋转矩阵，一般称为TBN矩阵
    * 世界空间到切线空间的转换矩阵为上述TBN矩阵的逆矩阵，因为是正交矩阵，所以逆矩阵就是它的转置矩阵
    * ![image](https://user-images.githubusercontent.com/74708198/237042985-d56c10a6-af46-4ed7-90bb-2da745399e82.png)

  * 转换矩阵完成之后，接下来就是光照计算
    * 将光照计算中需要的数据，例如光照方向、观察方向、法线方向等参数，带入到光照模型中计算

* 切线空间的优点
  * 法线存在各个空间里都可以，但关键不只是存在哪里，还有后续的光照计算
  * **切线空间的好处**
    * 自由度高
      * 模型空间下是绝对法线信息（仅可以用在创建它时的那个模型）
      * 而切线空间下的是相对法线信息，是对当前物体法线的扰动。（可以复用）
    * 可进行uv动画
      * 比如：移动uv坐标来实现凹凸移动效果
    * 可以重用法线纹理
      * 比如：一个立方体，6个面可以用一张法线贴图
    * 可压缩
      * 由于切线空间下贴图中法线的Z方向总是正方向（模型空间下可以是负的），那么我们只存**XY（切线和副切线）**就能推出**Z（法线）**了，可以少存一个

### 法线贴图在Unity中的压缩格式
* 在非移动平台上，会把法线贴图转化为DXRT5nm格式
  * 这个格式只有两个有效**AG通道（就是上边说的只存xy，推出z）** ，分别对应法线的y、x分量可以节省空间
* 但在移动平台上，使用传统RGB通道
* ![image](https://user-images.githubusercontent.com/74708198/237048232-8e4efe71-3428-477c-be69-249ef0c14cbd.png)
* ![image](https://user-images.githubusercontent.com/74708198/237048260-3694c4d5-a3b8-498e-8a08-37a20e5da244.png)

* **关于解码法线贴图时要做一个“*2-1”的操作的解释**
  * **法线纹理**中**存的就是表面法线**，由于法线分量范围为[-1,1]，像素的分量范围为[0,1] 因此`我们通常需要做一个映射：pixel=（normal+1）/2`，解码时就要做一个反向的操作
* 关于normal.xy * = scale；的解释
  * 是对法线的扰动效果进行缩放

## 视差映射 Parallax Mapping
### 原理
* 视差贴图Parallax Mapping，又称为 Offset Mapping，以及virtual displacement mapping)，于2001年由Kaneko引入，由Welsh进行了改进和推广
* 主要为了赋予模型`表面遮挡关系的细节`。引入了一张`高度图`
* 可以和法线贴图一起使用，来产生一些真实的效果
* 高度图一般视为顶点位移来使用，此时需要三角形足够多，模型足够精细，否则看起来会有块状
* 如果在有限的三角形面的情况下，怎么办？这就用到了视差映射技术
* **视差映射技术：**
  * `核心：改变纹理坐标`
  * 需要一张存储模型信息的高度图，利用模型表面高度信息来对纹理进行偏移（例如：低位置的信息被高位置的信息遮挡掉了，所以会采样更高的信息）
* ![image](https://user-images.githubusercontent.com/74708198/237049519-050e923f-600f-4c18-96ce-7cbf3380dd59.png)

### 视差映射的实现
* 和法线贴图一样，是欺骗眼睛的做法（只改变纹路，不增加三角形）

* 我们的模型在**切线空间**下，所有的点都位于切线和副切线组成的平面内（图中0.0蓝色线，即实际模型表面），但实际上物体要有更丰富的细节，所以我们希望它实际看起来应该是黑色的起伏感。
  * 例如图中的情况
  * 如果不使用视差贴图，要在当前视角下采样片元A点（黄色）的信息，得到的就是图中的`Ha`
  * 实际使用视差贴图时，真实的情况应该是视线和A点延长线和物体的交点，也就是B点，相应的就是`Hb`
  * ![image](https://user-images.githubusercontent.com/74708198/237051663-32dd993e-1cbc-4d08-a432-a67291f60915.png)


* **视差映射的具体算法：** 如何在知道A的uv值的情况下，算出B的uv值
  * 知道AB两者的偏移量即可
  * **偏移量的获得：**用近似的方法去求解
    * 首先拿A的高度信息进行采样，得到物体表面距离水平面（0.0）的深度值Ha
    * 用深度值Ha和视线的三角关系算出物体上等比的偏移方向，算出近似的B点（可以看到图中近似点B和实际点B还是有挺大差距的，所以模拟度比较低）
    * ![image](https://user-images.githubusercontent.com/74708198/237050690-abe5ebaf-4201-4b5a-ae2f-49b80b226e90.png)
    * ![image](https://user-images.githubusercontent.com/74708198/237050712-80401a1b-7d43-4d7b-ae96-c29e2b2b1a73.png)
    * ![image](https://user-images.githubusercontent.com/74708198/237050718-4c3d043b-add1-4c13-9bd2-dcd5241c3b3a.png)
    * 得到偏移之后B点的uv，再去对法线贴图进行采样、计算时，就不会采样A点了，而是B点
```HLSL
//视差映射
            float2 ParallaxMapping(float2 Huv, real3 viewDirTS)
            {
                float height = tex2D(_HeightMap, Huv).r;
                float2 offuv = viewDirTS.xy / viewDirTS.z * height * _HeightScale;

                return offuv;
            }
```



* **理解：视差贴图是如何产生遮挡效果的**
  * 当视线看到的是A点这样深度比较大的，那么视差贴图计算出的偏移值也是非常大的，这样A点最终被渲染出来的机会就比较小（偏移后就被采样到其他点上了）
  * 当视线看到B点这样深度比较小的点，计算出来的偏移就比较小，甚至原来点的附近，所以被采样的机会就比较大
  * 深度大的点很容易被深度小的点覆盖掉，这样就会表现出遮挡的效果
  * 明显精度较低

###  陡视差映射 Steep Parallax Mapping
* 也是近似解，但比视差映射精确
* 基本思想：
  * 将物体表面分为若干层，从最顶端开始采样，**每次沿着视角方向偏移一定的值**
  * 如果当前采样的层数，**大于**实际采样的层数，就停止采样。
    * 例如图中D点，采样到0.75层，实际是0.5层，就停止采样，返回偏移坐标
  * ![image](https://user-images.githubusercontent.com/74708198/237058013-0c847d86-2ea2-47b2-8e37-e80bec906a44.png)

* 陡视差映射的算法：（计算偏移点的过程）
  * 首先对A点采样，得到深度大约为0.8的位置，而其对应视线深度为0.0，不符合我们的基本思想，继续采样
  * 采样B点，深度为1，视线深度为0.25，不符合，继续采样
  * 采样C点，深度大约为0.8，视线深度为0.5，不符合，继续采样
  * 采样D点，采样深度为0.5，视线深度约为0.75，符合上述的条件，认为是比较合理的一个偏移点，就返回结果（return） 
```HLSL
//陡峭视差映射
            float2 SteepParallaxMapping(float2 uv, real3 viewDirTS)
            {
                float numLayers = 20.0;

                float layerHeight = 1.0 / numLayers;

                float currentLayerHeight = 0.0;

                float2 offlayerUV = viewDirTS.xy / viewDirTS.z * _HeightScale;

                float2 Stepping = offlayerUV / numLayers;

                float2 currentUV = uv;

                float2 AddUV = float2(0, 0);

                float currentHeightMapValue = tex2D(_HeightMap, currentUV + AddUV).r;

                for (int i = 0; i < numLayers; i++)
                {
                    if (currentLayerHeight > currentHeightMapValue)
                    {
                        return AddUV;
                    }
                    AddUV += Stepping;
                    currentHeightMapValue = tex2D(_HeightMap, currentUV + AddUV).r;
                    currentLayerHeight += layerHeight;
                }
                return AddUV;
            }
```

* 陡视差的问题：
  * 在于分层机制，如果
    * 分层多，性能开销就会大；
    * 分层小，渲染锯齿就比较明显。
  * 一种做法：可以根据视角v和法线n的角度限定采样层数
  * 锯齿问题会在浮雕贴图上做改善

## 浮雕映射 Relief Mapping
### 原理
* 可以更精确的计算uv偏移量(视差如果深度差较大偏移量也会较大就会失真)、提供更多的深度、还可以做自阴影以及闭塞效果
* 例如下图：可以看到浮雕的凹凸深度明显更大，且凹凸有自阴影效果
* ![image](https://user-images.githubusercontent.com/74708198/237059140-1e87d93f-c243-430d-9222-404842fd1e55.png)

### 实现
* 浮雕映射一般用**射线步进**和**二分查找**来**决定uv偏移量**
  * 第一步：射线步进部分，和视差贴图一样
  * 后边：二分查找部分：通过射线步进找到合适的步进后，在此步进内使用二分查找来找到精确的偏移值
* **为什么不直接使用二分查找？**
  * 会产生比较大的误差
  * 下图为例
    * 如果直接使用二分查找，在深度0和1的中间的1点，进一步为2点 -> 3点 ->Q点。但我们要的结果是P点，可以看到结果很明显是错误的
  * ![image](https://user-images.githubusercontent.com/74708198/237059659-8f3cbd7a-581b-45db-b59f-429a80df6263.png)

```HLSL
//浮雕贴图
            float2 ReliefMapping(float2 uv, real3 viewDirTS)
            {
                float2 offlayerUV = viewDirTS.xy / viewDirTS.z * _HeightScale;
                float RayNumber = 20;
                float layerHeight = 1.0 / RayNumber;
                float2 SteppingUV = offlayerUV / RayNumber;
                float offlayerUVL = length(offlayerUV);
                float currentLayerHeight = 0;
                
                float2 offuv= float2(0,0);
                for (int i = 0; i < RayNumber; i++)
                {
                    offuv += SteppingUV;

                    float currentHeight = tex2D(_HeightMap, uv + offuv).r;
                    currentLayerHeight += layerHeight;
                    if (currentHeight < currentLayerHeight)
                    {
                        break;
                    }
                }

                float2 T0 = uv-SteppingUV, T1 = uv + offuv;

                for (int j = 0;j<20;j++)
                {
                    float2 P0 = (T0 + T1) / 2;

                    float P0Height = tex2D(_HeightMap, P0).r;

                    float P0LayerHeight = length(P0) / offlayerUVL;

                    if (P0Height < P0LayerHeight)
                    {
                        T0 = P0;

                    }
                    else
                    {
                        T1= P0;
                    }

                }

                return (T0 + T1) / 2 - uv;
            }
```

### 视差闭塞贴图（POM = Parallax  Occlusion Mapping）
* 相对于浮雕贴图，不同之处在于最后一步
  * 浮雕贴图是在确认最后步进之后进行二分查找（在迭代次数比较多的情况下，还是挺耗的）
  * 视差闭塞贴图是在最后步进的两端uv值进行采样（下图红色箭头），采样之后再对这两个结果进行插值，插值的结果作为P点最终的偏移值
  * ![image](https://user-images.githubusercontent.com/74708198/237062658-6a3794ae-c3b5-4b36-828f-898dafb88e14.png)
* 优点：
  * 相对于浮雕映射，性能更好（最后只做插值，而浮雕要做二分查找）
  * 相对于陡视差贴图，精确性更好
* 要求：
  * 因为最后要做插值，所以要求表面是相对比较平滑/连续的，如果有莫名的凸起结果可能会出错

## 还原法线映射、视差映射、浮雕映射
```HLSL
Shader "Bump Mapping"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}

        [Toggle(_NORMALMAP)] _EnableBumpMap("Enable Normal/Bump Map", Float) = 0.0
        _NormalMap("NormalMap",2D) = "bump" {}
        _NormalScale("NormalScale" ,Float) = 1

        [Toggle(_HEIGHTMAP)] _EnableHeightMap("Enable Height Map",Float) = 0.0
        [Toggle(_RELIEFMAP)] _EnableReliefMap("Enable Relief Map",Float) = 0.0
        _HeightMap("HeigheMap",2D) = "white"{}
        _HeightScale("HeightScale",range(0,0.5)) = 0.005

        _Smoothness("Smoothness",range(0,2)) = 0.5
        _Metallic("Metallic",range(0,1)) = 0.2
    }
    SubShader
    {
        Tags
        {
            "RenderType"="Opaque"
        }
        LOD 100

        HLSLINCLUDE
        // Material Keywords
        #pragma shader_feature _NORMALMAP
        #pragma shader_feature _HEIGHTMAP
        #pragma shader_feature _RELIEFMAP
        //#pragma shader_feature _SPECULAR_COLOR

        #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
        #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
        ENDHLSL

        Pass
        {
            Name "URPLighting"
            Tags
            {
                "LightMode" = "UniversalForward"
            }

            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag

            struct appdata
            {
                float4 positionOS : POSITION;
                float3 normalOS : NORMAL;
                float2 uv : TEXCOORD0;

                float4 tangentOS : TANGENT;
            };

            struct v2f
            {
                float4 positionCS : SV_POSITION;
                float3 normalWS:TEXCOORD0;
                float3 viewDirWS:TEXCOORD1;

                // Note this macro is using TEXCOORD2
                DECLARE_LIGHTMAP_OR_SH(lightmapUV, vertexSH, 2);
                float4 uv : TEXCOORD3;
                #if defined(_HEIGHTMAP) || defined (_NORMALMAP)
				float4 tangentWS:TEXCOORD4;
                #endif
                #ifdef _HEIGHTMAP
                   float4 uv2 : TEXCOORD5;        
                #endif
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;
            float _Smoothness;
            sampler2D _NormalMap;
            float4 _NormalMap_ST;
            float _Metallic;
            float _NormalScale;
            sampler2D _HeightMap;
            float4 _HeightMap_ST;
            float _HeightScale;

            v2f vert(appdata v)
            {
                v2f o;
                VertexPositionInputs positionInputs = GetVertexPositionInputs(v.positionOS.xyz);

                o.positionCS = positionInputs.positionCS;
                o.viewDirWS = GetWorldSpaceViewDir(positionInputs.positionWS);

                o.uv.xy = TRANSFORM_TEX(v.uv, _MainTex);
                VertexNormalInputs normalInputs = GetVertexNormalInputs(v.normalOS, v.tangentOS);
                o.normalWS = normalInputs.normalWS;


                #if defined (_HEIGHTMAP) ||  defined (_NORMALMAP)
                     real sign = v.tangentOS.w * GetOddNegativeScale();
				     half4 tangentWS = half4(normalInputs.tangentWS.xyz, sign);
                     o.tangentWS = tangentWS;
                #endif

                #ifdef _NORMALMAP
                    o.uv.zw = TRANSFORM_TEX(v.uv, _NormalMap);

                #endif
                #ifdef _HEIGHTMAP
                     o.uv2.xy = TRANSFORM_TEX(v.uv, _HeightMap);
                #endif

                OUTPUT_SH(normalInputs.normalWS.xyz, o.vertexSH);
                return o;
            }

            //视差映射
            float2 ParallaxMapping(float2 Huv, real3 viewDirTS)
            {
                float height = tex2D(_HeightMap, Huv).r;
                float2 offuv = viewDirTS.xy / viewDirTS.z * height * _HeightScale;

                return offuv;
            }

            //陡峭视差映射
            float2 SteepParallaxMapping(float2 uv, real3 viewDirTS)
            {
                float numLayers = 20.0;

                float layerHeight = 1.0 / numLayers;

                float currentLayerHeight = 0.0;

                float2 offlayerUV = viewDirTS.xy / viewDirTS.z * _HeightScale;

                float2 Stepping = offlayerUV / numLayers;

                float2 currentUV = uv;

                float2 AddUV = float2(0, 0);

                float currentHeightMapValue = tex2D(_HeightMap, currentUV + AddUV).r;

                for (int i = 0; i < numLayers; i++)
                {
                    if (currentLayerHeight > currentHeightMapValue)
                    {
                        return AddUV;
                    }
                    AddUV += Stepping;
                    currentHeightMapValue = tex2D(_HeightMap, currentUV + AddUV).r;
                    currentLayerHeight += layerHeight;
                }
                return AddUV;
            }

            //浮雕贴图
            float2 ReliefMapping(float2 uv, real3 viewDirTS)
            {
                float2 offlayerUV = viewDirTS.xy / viewDirTS.z * _HeightScale;
                float RayNumber = 20;
                float layerHeight = 1.0 / RayNumber;
                float2 SteppingUV = offlayerUV / RayNumber;
                float offlayerUVL = length(offlayerUV);
                float currentLayerHeight = 0;
                
                float2 offuv= float2(0,0);
                for (int i = 0; i < RayNumber; i++)
                {
                    offuv += SteppingUV;

                    float currentHeight = tex2D(_HeightMap, uv + offuv).r;
                    currentLayerHeight += layerHeight;
                    if (currentHeight < currentLayerHeight)
                    {
                        break;
                    }
                }

                float2 T0 = uv-SteppingUV, T1 = uv + offuv;

                for (int j = 0;j<20;j++)
                {
                    float2 P0 = (T0 + T1) / 2;

                    float P0Height = tex2D(_HeightMap, P0).r;

                    float P0LayerHeight = length(P0) / offlayerUVL;

                    if (P0Height < P0LayerHeight)
                    {
                        T0 = P0;

                    }
                    else
                    {
                        T1= P0;
                    }

                }

                return (T0 + T1) / 2 - uv;
            }

            half4 frag(v2f i) : SV_Target
            {
                #if defined(_HEIGHTMAP) || defined (_NORMALMAP)

                float sgn = i.tangentWS.w;

				float3 bitangent = sgn * cross(i.normalWS.xyz, i.tangentWS.xyz);
                half3x3 T2W = half3x3(i.tangentWS.xyz, bitangent.xyz, i.normalWS.xyz);
                
                #endif

                float3 viewDirWS = normalize(i.viewDirWS);
                //视差映射
                #ifdef _HEIGHTMAP
                    real3 viewDirTS = normalize(TransformWorldToTangent(-viewDirWS.xyz,T2W));
                    float2 offuv = float2(0,0);
                    #ifdef _RELIEFMAP
                        offuv = ReliefMapping( i.uv2.xy, viewDirTS);  //陡峭视差映射
                    #else
                        offuv = ParallaxMapping( i.uv2.xy, viewDirTS); //普通视差映射
                    #endif

                    i.uv.xy += offuv;
                    i.uv.zw += offuv;
                
                #endif
                // sample the texture
                half4 col = tex2D(_MainTex, i.uv.xy);

                // URP 光照
                SurfaceData surfaceData = (SurfaceData)0;

                surfaceData.albedo = col;
                surfaceData.alpha = col.a;
                surfaceData.smoothness = _Smoothness;
                surfaceData.metallic = _Metallic;
                surfaceData.occlusion = 1;
                InputData inputData = (InputData)0;
                inputData.viewDirectionWS = viewDirWS;
                //法线映射
                #ifdef _NORMALMAP
                 float3 normalTS = UnpackNormalScale(tex2D(_NormalMap,i.uv.zw), _NormalScale);
				 i.normalWS = TransformTangentToWorld(normalTS, T2W);
                #endif

                inputData.bakedGI = SAMPLE_GI(i.lightmapUV, i.vertexSH, i.normalWS);
                inputData.normalWS = i.normalWS;

                half4 color = UniversalFragmentPBR(inputData, surfaceData.albedo, surfaceData.metallic,
                                                   surfaceData.specular, surfaceData.smoothness, surfaceData.occlusion,
                                                   surfaceData.emission, surfaceData.alpha);

                return color;
            }
            ENDHLSL
        }
    }
}
```

## 具体实践
* 在UE4中用多层视差做了冰的效果
  * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/d925c117-7541-4441-b08a-b586a36803bf)
* 法线还可以用来对uv进行扰动，比如用在后处理的破碎玻璃效果，不过想要效果做得好的话，对法线贴图的要求比较高，最好做出高度差的效果贴一下之前做得一个效果
  * ![image](https://github.com/ThereAreBearsComing/aBookOFtechArt/assets/74708198/ea7908ed-f912-44b4-9f47-a2e1efba7c44)

### REF:
* 利用视差做冰材质
  * https://blog.csdn.net/leelizc/article/details/78609282 
* 《Real-Time Rendering 3rd》 提炼总结(五) 第六章 · 纹理贴图及相关技-毛星云
  * https://zhuanlan.zhihu.com/p/27551369
* UE4材质视差算法
  * https://zhuanlan.zhihu.com/p/150949320
* 原笔记
  * https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/nspda5#7xx3r


